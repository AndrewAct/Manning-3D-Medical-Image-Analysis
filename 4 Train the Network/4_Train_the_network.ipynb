{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "4. Train the network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VbXLWxvakGd",
        "colab_type": "text"
      },
      "source": [
        "# Medical image analysis with PyTorch\n",
        "\n",
        "Create a deep convolutional network for an image translation task with PyTorch from scratch and train it on a subset of the IXI dataset for a T1-w to T2-w transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMEVHtsQakHg",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6IsTOoakHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_split = 0.1\n",
        "batch_size = 16\n",
        "n_jobs = 12\n",
        "n_epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcRgNZ-EakHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = Compose([RandomCrop3D((128,128,32)), ToTensor()])\n",
        "\n",
        "# set up training and validation data loader for nifti images\n",
        "dataset = NiftiDataset(t1_dir, t2_dir, tfms, preload=False)  # set preload=False if you have limited CPU memory\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(valid_split * num_train)\n",
        "valid_idx = np.random.choice(indices, size=split, replace=False)\n",
        "train_idx = list(set(indices) - set(valid_idx))\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size,\n",
        "                          num_workers=n_jobs, pin_memory=True)\n",
        "valid_loader = DataLoader(dataset, sampler=valid_sampler, batch_size=batch_size,\n",
        "                          num_workers=n_jobs, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k7lcMnGakHj",
        "colab_type": "text"
      },
      "source": [
        "### Milestone 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xTvuKC9akHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert torch.cuda.is_available()\n",
        "device = torch.device('cuda:0')\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm9hqmn9akHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Unet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwGhrHU2akHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_state_dict(torch.load('trained.pth'));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K044-y4cakHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda(device=device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-6)\n",
        "criterion = nn.SmoothL1Loss()  #nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvcONTuwakHs",
        "colab_type": "code",
        "colab": {},
        "outputId": "b161d800-a619-4301-b5be-e12c44d13271"
      },
      "source": [
        "train_losses, valid_losses = [], []\n",
        "n_batches = len(train_loader)\n",
        "for t in range(1, n_epochs + 1):\n",
        "    # training\n",
        "    t_losses = []\n",
        "    model.train(True)\n",
        "    for i, (src, tgt) in enumerate(train_loader):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(src)\n",
        "        loss = criterion(out, tgt)\n",
        "        t_losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_losses.append(t_losses)\n",
        "\n",
        "    # validation\n",
        "    v_losses = []\n",
        "    model.train(False)\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for src, tgt in valid_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            out = model(src)\n",
        "            loss = criterion(out, tgt)\n",
        "            v_losses.append(loss.item())\n",
        "        valid_losses.append(v_losses)\n",
        "\n",
        "    if not np.all(np.isfinite(t_losses)): \n",
        "        raise RuntimeError('NaN or Inf in training loss, cannot recover. Exiting.')\n",
        "    log = f'Epoch: {t} - Training Loss: {np.mean(t_losses):.2e}, Validation Loss: {np.mean(v_losses):.2e}'\n",
        "    print(log)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Training Loss: 1.44e-01, Validation Loss: 8.80e-01\n",
            "Epoch: 2 - Training Loss: 1.20e-01, Validation Loss: 2.06e-01\n",
            "Epoch: 3 - Training Loss: 1.17e-01, Validation Loss: 1.63e-01\n",
            "Epoch: 4 - Training Loss: 1.09e-01, Validation Loss: 1.21e-01\n",
            "Epoch: 5 - Training Loss: 1.05e-01, Validation Loss: 1.01e-01\n",
            "Epoch: 6 - Training Loss: 1.01e-01, Validation Loss: 1.06e-01\n",
            "Epoch: 7 - Training Loss: 1.04e-01, Validation Loss: 3.73e-01\n",
            "Epoch: 8 - Training Loss: 1.02e-01, Validation Loss: 1.15e-01\n",
            "Epoch: 9 - Training Loss: 1.01e-01, Validation Loss: 1.97e-01\n",
            "Epoch: 10 - Training Loss: 9.05e-02, Validation Loss: 1.41e-01\n",
            "Epoch: 11 - Training Loss: 8.75e-02, Validation Loss: 9.73e-02\n",
            "Epoch: 12 - Training Loss: 9.25e-02, Validation Loss: 1.21e-01\n",
            "Epoch: 13 - Training Loss: 8.07e-02, Validation Loss: 1.14e-01\n",
            "Epoch: 14 - Training Loss: 9.38e-02, Validation Loss: 1.12e-01\n",
            "Epoch: 15 - Training Loss: 9.20e-02, Validation Loss: 8.68e-02\n",
            "Epoch: 16 - Training Loss: 8.71e-02, Validation Loss: 9.11e-02\n",
            "Epoch: 17 - Training Loss: 8.63e-02, Validation Loss: 8.77e-02\n",
            "Epoch: 18 - Training Loss: 8.17e-02, Validation Loss: 9.69e-02\n",
            "Epoch: 19 - Training Loss: 8.32e-02, Validation Loss: 8.04e-02\n",
            "Epoch: 20 - Training Loss: 8.91e-02, Validation Loss: 2.12e-01\n",
            "Epoch: 21 - Training Loss: 9.98e-02, Validation Loss: 7.94e-02\n",
            "Epoch: 22 - Training Loss: 8.58e-02, Validation Loss: 9.54e-02\n",
            "Epoch: 23 - Training Loss: 8.66e-02, Validation Loss: 8.81e-02\n",
            "Epoch: 24 - Training Loss: 8.22e-02, Validation Loss: 1.77e-01\n",
            "Epoch: 25 - Training Loss: 7.61e-02, Validation Loss: 7.83e-02\n",
            "Epoch: 26 - Training Loss: 7.91e-02, Validation Loss: 1.23e-01\n",
            "Epoch: 27 - Training Loss: 7.53e-02, Validation Loss: 7.28e-02\n",
            "Epoch: 28 - Training Loss: 7.57e-02, Validation Loss: 6.92e-02\n",
            "Epoch: 29 - Training Loss: 8.08e-02, Validation Loss: 8.17e-02\n",
            "Epoch: 30 - Training Loss: 7.74e-02, Validation Loss: 8.11e-02\n",
            "Epoch: 31 - Training Loss: 8.36e-02, Validation Loss: 8.37e-02\n",
            "Epoch: 32 - Training Loss: 8.11e-02, Validation Loss: 8.54e-02\n",
            "Epoch: 33 - Training Loss: 7.36e-02, Validation Loss: 6.93e-02\n",
            "Epoch: 34 - Training Loss: 7.37e-02, Validation Loss: 8.33e-02\n",
            "Epoch: 35 - Training Loss: 7.40e-02, Validation Loss: 8.86e-02\n",
            "Epoch: 36 - Training Loss: 7.45e-02, Validation Loss: 7.63e-02\n",
            "Epoch: 37 - Training Loss: 8.08e-02, Validation Loss: 1.75e-01\n",
            "Epoch: 38 - Training Loss: 7.84e-02, Validation Loss: 8.48e-02\n",
            "Epoch: 39 - Training Loss: 7.70e-02, Validation Loss: 8.39e-02\n",
            "Epoch: 40 - Training Loss: 7.06e-02, Validation Loss: 8.10e-02\n",
            "Epoch: 41 - Training Loss: 7.31e-02, Validation Loss: 1.04e-01\n",
            "Epoch: 42 - Training Loss: 7.48e-02, Validation Loss: 8.68e-02\n",
            "Epoch: 43 - Training Loss: 6.78e-02, Validation Loss: 2.42e-01\n",
            "Epoch: 44 - Training Loss: 6.52e-02, Validation Loss: 1.16e-01\n",
            "Epoch: 45 - Training Loss: 6.64e-02, Validation Loss: 1.09e-01\n",
            "Epoch: 46 - Training Loss: 6.59e-02, Validation Loss: 9.96e-02\n",
            "Epoch: 47 - Training Loss: 6.75e-02, Validation Loss: 6.96e-02\n",
            "Epoch: 48 - Training Loss: 6.69e-02, Validation Loss: 9.90e-02\n",
            "Epoch: 49 - Training Loss: 6.99e-02, Validation Loss: 7.00e-02\n",
            "Epoch: 50 - Training Loss: 7.23e-02, Validation Loss: 7.79e-02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEgRD9n8akHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'trained.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}